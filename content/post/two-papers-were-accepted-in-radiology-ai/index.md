---
title: One paper was accepted in Radiology AI
date: 2022-07-07T03:46:08.917Z
summary: Good News! We have two papers accepted in Radiology AI
draft: false
featured: false
image:
  filename: ryai.jpg
  focal_point: Smart
  preview_only: false
---
<!--StartFragment-->

**[Rethinking Annotation Granularity for Overcoming Shortcuts in Deep Learning–based Radiograph Diagnosis: A Multicenter Study](https://pubs.rsna.org/doi/abs/10.1148/ryai.210299)**

Fine-grained annotations (ie, lesion bounding boxes) help chest radiograph diagnosis models overcome learning shortcuts by enabling the models to identify the correct lesion areas, leading to significantly improved radiograph-level classification performance. <!--StartFragment-->

Two DL models were developed using radiograph-level annotations (disease present: yes or no) and fine-grained lesion-level annotations (lesion bounding boxes), respectively named CheXNet and CheXDet. A total of 34 501 chest radiographs obtained from January 2005 to September 2019 were retrospectively collected and annotated regarding cardiomegaly, pleural effusion, mass, nodule, pneumonia, pneumothorax, tuberculosis, fracture, and aortic calcification. The internal classification performance and lesion localization performance of the models were compared on a testing set (*n* = 2922); external classification performance was compared on National Institutes of Health (NIH) Google (*n* = 4376) and PadChest (*n* = 24 536) datasets; and external lesion localization performance was compared on the NIH ChestX-ray14 dataset (*n* = 880). The models were also compared with radiologist performance on a subset of the internal testing set (*n* = 496). Performance was evaluated using receiver operating characteristic (ROC) curve analysis.

<!--EndFragment-->